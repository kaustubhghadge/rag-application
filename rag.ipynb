{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# This is the YouTube video we're going to use.\n",
    "YOUTUBE_VIDEO = \"https://youtu.be/sVC4_yK0hr8?feature=shared\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a langchain parser so that we can skip the AIMessage() object that is being returned from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing Youtube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "\n",
    "\n",
    "# Check if we have created the transcription file yet. If not, then create one.\n",
    "if not os.path.exists(\"short_transcription.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # Let's load the base model. This is not the most accurate\n",
    "    # model but it's fast.\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
    "\n",
    "        with open(\"short_transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the transcription file into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"short_transcription.txt\")\n",
    "text_documents = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "index_name = \"rag-application\"\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    documents, \n",
    "    embeddings, \n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shrimp industry in India is booming and has become one of the leading\n",
      "exporters of shrimp. However, it has raised concerns about labor abuse,\n",
      "environmental damage, and the use of antibiotics in shrimp production.\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"What's going on with shrimp industry in India?\")\n",
    "\n",
    "formatted_response = textwrap.fill(response, width=80)\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate response to Marathi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from operator import itemgetter\n",
    "\n",
    "# translation_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"Translate {answer} to {language}\"\n",
    "# )\n",
    "\n",
    "# translation_chain = (\n",
    "#     {\"answer\": chain, \"language\": itemgetter(\"language\")} \n",
    "#     | translation_prompt \n",
    "#     | model \n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "# #Answering in Marathi\n",
    "# translation_chain.invoke(\n",
    "#     {   \"question\":\"Summarize\",\n",
    "#         \"language\": \"Marathi\"\n",
    "#     }\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
